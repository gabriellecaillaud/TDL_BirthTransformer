{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "import itertools\n",
    "import logging\n",
    "import random\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import functional as F\n",
    "from typing import List, Optional, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "from dataset import DataArgs, Dataset, iterate_batches\n",
    "from basic_model import ModelArgs, Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class OptimArgs:\n",
    "    learning_rate: float = 0.2  # for SGD\n",
    "    weight_decay: float = 1e-4  # for SGD\n",
    "    momentum: float = 0.9  # for SGD\n",
    "    batch_size: int = 512\n",
    "    use_sgd: bool = True  # otherwise use AdamW\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainerArgs:\n",
    "    optim_args: OptimArgs\n",
    "    data_args: DataArgs\n",
    "    model_args: ModelArgs\n",
    "    max_iters: Optional[int] = None\n",
    "    eval_delta: int = 5\n",
    "    log_norms: bool = False\n",
    "    log_probes: bool = False\n",
    "    freeze_until: str = ''\n",
    "    loss_head_only: bool = True\n",
    "    bigram_outs_train: bool = False\n",
    "    bigram_outs_test: bool = False\n",
    "    num_data_workers: int = 60\n",
    "    seed: int = 42\n",
    "    save_dir: Optional[str] = None\n",
    "    root_dir: str = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    " args = TrainerArgs(\n",
    "           optim_args=OptimArgs(),\n",
    "           data_args=DataArgs(),\n",
    "           model_args=ModelArgs()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.merge(OmegaConf.structured(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset(cfg.data_args, train_test=None, bigram_outs=cfg.bigram_outs_train)\n",
    "ds_test = Dataset(cfg.data_args, train_test=None, bigram_outs=cfg.bigram_outs_test)\n",
    "ds_test.idxs = ds.idxs\n",
    "cfg.model_args.vocab_size = ds.num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (tok_embeddings): Embedding(65, 64)\n",
       "  (layers): ModuleList(\n",
       "    (0-1): 2 x TransformerBlock(\n",
       "      (attention): Attention(\n",
       "        (wq): Identity()\n",
       "        (wk): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (wv): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (wo): Linear(in_features=64, out_features=64, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output): Linear(in_features=64, out_features=65, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  \n",
    "model = Transformer(cfg.model_args)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add attention hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f1fae047ee0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_features = None\n",
    "attn_features2 = None\n",
    "attn_input_features = None\n",
    "attn_scores = None\n",
    "attn_scores2 = None\n",
    "def attn0_hook(_, inp, outp):\n",
    "    global attn_features, attn_input_features, attn_scores\n",
    "    attn_input_features = inp[0].detach()\n",
    "    attn_features = outp[0].detach()\n",
    "    attn_scores = outp[1].detach()\n",
    "model.layers[0].attention.register_forward_hook(attn0_hook)\n",
    "def attn1_hook(_, inp, outp):\n",
    "    global attn_scores2, attn_features2\n",
    "    attn_features2 = outp[0].detach()\n",
    "    attn_scores2 = outp[1].detach()\n",
    "model.layers[1].attention.register_forward_hook(attn1_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory probes\n",
    "range_toks = torch.from_numpy(np.arange(ds.n_train_toks)).to(device)\n",
    "def test_wo1():\n",
    "    toks = model.tok_embeddings(range_toks)\n",
    "    toks = model.layers[1].attention.wv(toks)\n",
    "    toks = model.layers[1].attention.wo(toks)\n",
    "    toks = model.output(toks)\n",
    "    return (toks.argmax(-1) == range_toks).float().mean().item()\n",
    "\n",
    "full_range_toks = torch.from_numpy(np.arange(ds.num_tokens)).to(device)\n",
    "conds = torch.from_numpy(np.array(ds.cond)).to(device)\n",
    "used_idxs = np.arange(ds.num_tokens)\n",
    "if cfg.data_args.fixed_special_toks:\n",
    "    used_idxs = np.setdiff1d(used_idxs, ds.idxs)\n",
    "def test_ff1():\n",
    "    toks = model.tok_embeddings(full_range_toks[used_idxs])\n",
    "    toks = model.layers[1].ff(toks)\n",
    "    toks = model.output(toks)\n",
    "    return F.kl_div(F.log_softmax(toks, dim=1), conds[used_idxs], reduction='batchmean').item()\n",
    "\n",
    "range_pos_toks = torch.from_numpy(np.arange(cfg.model_args.max_length)).to(device)\n",
    "def test_wk0(cutoff=None):\n",
    "    pe = model.pe[:cutoff,:]\n",
    "    k = model.layers[0].attention.wk(pe[:-1])\n",
    "    q = model.layers[0].attention.wq(pe[1:])\n",
    "    return ((q @ k.t()).argmax(-1) == range_pos_toks[:pe.shape[0]-1]).float().mean().item()\n",
    "\n",
    "wk1_range_toks = full_range_toks.clone()\n",
    "if cfg.data_args.fixed_special_toks:\n",
    "    wk1_range_toks = wk1_range_toks[ds.idxs]\n",
    "def test_wk1():\n",
    "    toksk = model.tok_embeddings(wk1_range_toks)\n",
    "    toksk = model.layers[0].attention.wv(toksk)\n",
    "    toksk = model.layers[0].attention.wo(toksk)\n",
    "    toksk = model.layers[1].attention.wk(toksk)\n",
    "\n",
    "    toksq = model.tok_embeddings(wk1_range_toks)\n",
    "    toksq = model.layers[1].attention.wq(toksq)\n",
    "    return ((toksq @ toksk.t()).argmax(-1) == range_toks[:wk1_range_toks.shape[0]]).float().mean().item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.freeze_until"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok_embeddings.weight', 'layers.0.attention.wk.weight', 'layers.0.attention.wv.weight', 'layers.0.attention.wo.weight', 'layers.1.attention.wk.weight', 'layers.1.attention.wv.weight', 'layers.1.attention.wo.weight', 'output.weight']\n"
     ]
    }
   ],
   "source": [
    "# available params to potentially freeze:\n",
    "print( list(name for name, p in model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.freeze_until = \"300:layers.1.attention.wo.weight\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial param freezing\n",
    "freeze_until = defaultdict(list)\n",
    "to_freeze = []\n",
    "if cfg.freeze_until:\n",
    "    for kv in cfg.freeze_until.split(','):\n",
    "        k, v = kv.split(':')\n",
    "        k = int(k)\n",
    "        to_freeze.append(v)\n",
    "        freeze_until[k].append(v)\n",
    "\n",
    "    for name, p in model.named_parameters():\n",
    "        if name in to_freeze:\n",
    "            p.requires_grad_(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {300: ['layers.1.attention.wo.weight']})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freeze_until"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.optim_args.use_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.optim_args.use_sgd:\n",
    "    optimizer = torch.optim.SGD(model.parameters(),\n",
    "            lr=cfg.optim_args.learning_rate,\n",
    "            weight_decay=cfg.optim_args.weight_decay,\n",
    "            momentum=cfg.optim_args.momentum)\n",
    "else:\n",
    "    optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=cfg.optim_args.learning_rate,\n",
    "            weight_decay=cfg.optim_args.weight_decay,\n",
    "            betas=(0.9, 0.95),\n",
    "            eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a test batch for experimentation\n",
    "x_exp, out_exp = ds.gen_batch(np.random.default_rng(0), 128)\n",
    "x_exp = x_exp[:,:ds.seq_length]\n",
    "\n",
    "# OOD test data\n",
    "x_test, out_test = ds_test.gen_batch(np.random.default_rng(0), 512)\n",
    "x_t = torch.from_numpy(x_test[:,:ds.seq_length]).to(device)\n",
    "y_t = torch.from_numpy(x_test[:,1:ds.seq_length + 1]).to(device)\n",
    "outs_t = torch.from_numpy(out_test[:,:ds.seq_length]).to(device)\n",
    "\n",
    "t = time.time()\n",
    "t0 = t\n",
    "res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(cfg.root_dir)\n",
    "print(cfg.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.save_dir=(\"./logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.save_dir is not None:\n",
    "    outdir = Path(cfg.root_dir) / Path(cfg.save_dir)\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    # save params\n",
    "    with open(outdir / 'params.json', 'w') as f:\n",
    "        json.dump(dict(cfg), f, sort_keys=True, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = open(outdir / 'res.jsonl', 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract from paper: \n",
    "We train our models using mini-batch SGD with momentum, where each\n",
    "batch consists of 512 fresh sequences of length T = 256 sampled from our synthetic model. We use\n",
    "a fixed learning rate and weight decay. Hyperparameters are given in Appendix E. Unless otherwise\n",
    "noted, we use d = 128, random triggers with πq = πu and uniform output tokens. The reported\n",
    "accuracies and losses are computed over each fresh batch before it is used for optimization, and\n",
    "are averaged over relevant tokens: “in-context accuracy/loss” numbers only consider predictions\n",
    "of output tokens on triggers starting at the second occurrence (the first is non-deterministic), while\n",
    "“global loss” refers to average loss on non-trigger tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(cfg.max_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.max_iters =1000\n",
    "cfg.eval_delta = 5\n",
    "# number of triggers\n",
    "cfg.data_args.k = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_args.k=5 data_args.fixed_special_toks=True \\\n",
    "        optim_args.use_sgd=True optim_args.learning_rate=0.03 optim_args.weight_decay=1e-4 optim_args.batch_size=512 \\\n",
    "        model_args.final_ffn=False model_args.freeze_embeddings=True model_args.freeze_output=True model_args.dim=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optim_args': {'learning_rate': 0.2, 'weight_decay': 0.0001, 'momentum': 0.9, 'batch_size': 512, 'use_sgd': True}, 'data_args': {'k': 0, 'seq_length': 256, 'show_latents': False, 'fixed_special_toks': False, 'special_toks_offset': 0, 'output_counter': True, 'no_repeat': False}, 'model_args': {'vocab_size': 65, 'dim': 64, 'max_length': 256, 'final_ffn': False, 'first_ffn': False, 'linear_final_ffn': True, 'linear_first_ffn': True, 'freeze_embeddings': False, 'freeze_output': False, 'tie_output': False, 'use_rope': False, 'sqrtd_embeddings': False, 'no_sqrtd': False, 'sin_cos': False}, 'max_iters': None, 'eval_delta': 5, 'log_norms': False, 'log_probes': False, 'freeze_until': '300:layers.1.attention.wo.weight', 'loss_head_only': True, 'bigram_outs_train': False, 'bigram_outs_test': False, 'num_data_workers': 60, 'seed': 42, 'save_dir': './logs', 'root_dir': ''}\n"
     ]
    }
   ],
   "source": [
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConfigAttributeError",
     "evalue": "Key 'fixed_special_tokens' not in 'DataArgs'\n    full_key: data_args.fixed_special_tokens\n    reference_type=DataArgs\n    object_type=DataArgs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConfigAttributeError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_special_tokens\u001b[49m\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39muse_sgd\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39mlearning_rate\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/altegrad/venv_altegrad/lib/python3.10/site-packages/omegaconf/dictconfig.py:359\u001b[0m, in \u001b[0;36mDictConfig.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_and_raise(\n\u001b[1;32m    356\u001b[0m         key\u001b[38;5;241m=\u001b[39mkey, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cause\u001b[38;5;241m=\u001b[39me, type_override\u001b[38;5;241m=\u001b[39mConfigAttributeError\n\u001b[1;32m    357\u001b[0m     )\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_and_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcause\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/altegrad/venv_altegrad/lib/python3.10/site-packages/omegaconf/base.py:231\u001b[0m, in \u001b[0;36mNode._format_and_raise\u001b[0;34m(self, key, value, cause, msg, type_override)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_format_and_raise\u001b[39m(\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    225\u001b[0m     key: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m     type_override: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    230\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     \u001b[43mformat_and_raise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcause\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcause\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcause\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtype_override\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_override\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/altegrad/venv_altegrad/lib/python3.10/site-packages/omegaconf/_utils.py:819\u001b[0m, in \u001b[0;36mformat_and_raise\u001b[0;34m(node, key, value, msg, cause, type_override)\u001b[0m\n\u001b[1;32m    817\u001b[0m         ex \u001b[38;5;241m=\u001b[39m type_override(\u001b[38;5;28mstr\u001b[39m(cause))\n\u001b[1;32m    818\u001b[0m         ex\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(cause\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m)\n\u001b[0;32m--> 819\u001b[0m     \u001b[43m_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcause\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m object_type: Optional[Type[Any]]\n\u001b[1;32m    822\u001b[0m object_type_str: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/altegrad/venv_altegrad/lib/python3.10/site-packages/omegaconf/_utils.py:797\u001b[0m, in \u001b[0;36m_raise\u001b[0;34m(ex, cause)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    796\u001b[0m     ex\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 797\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex\u001b[38;5;241m.\u001b[39mwith_traceback(sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/altegrad/venv_altegrad/lib/python3.10/site-packages/omegaconf/dictconfig.py:351\u001b[0m, in \u001b[0;36mDictConfig.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m()\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_DEFAULT_MARKER_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConfigKeyError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_and_raise(\n\u001b[1;32m    356\u001b[0m         key\u001b[38;5;241m=\u001b[39mkey, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cause\u001b[38;5;241m=\u001b[39me, type_override\u001b[38;5;241m=\u001b[39mConfigAttributeError\n\u001b[1;32m    357\u001b[0m     )\n",
      "File \u001b[0;32m~/altegrad/venv_altegrad/lib/python3.10/site-packages/omegaconf/dictconfig.py:442\u001b[0m, in \u001b[0;36mDictConfig._get_impl\u001b[0;34m(self, key, default_value, validate_key)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_impl\u001b[39m(\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28mself\u001b[39m, key: DictKeyType, default_value: Any, validate_key: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    440\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 442\u001b[0m         node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_child\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthrow_on_missing_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_key\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (ConfigAttributeError, ConfigKeyError):\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m default_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _DEFAULT_MARKER_:\n",
      "File \u001b[0;32m~/altegrad/venv_altegrad/lib/python3.10/site-packages/omegaconf/basecontainer.py:73\u001b[0m, in \u001b[0;36mBaseContainer._get_child\u001b[0;34m(self, key, validate_access, validate_key, throw_on_missing_value, throw_on_missing_key)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_child\u001b[39m(\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     66\u001b[0m     key: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m     throw_on_missing_key: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     71\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Optional[Node], List[Optional[Node]]]:\n\u001b[1;32m     72\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Like _get_node, passing through to the nearest concrete Node.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     child \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_access\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthrow_on_missing_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrow_on_missing_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthrow_on_missing_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrow_on_missing_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(child, UnionNode) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_special(child):\n\u001b[1;32m     81\u001b[0m         value \u001b[38;5;241m=\u001b[39m child\u001b[38;5;241m.\u001b[39m_value()\n",
      "File \u001b[0;32m~/altegrad/venv_altegrad/lib/python3.10/site-packages/omegaconf/dictconfig.py:475\u001b[0m, in \u001b[0;36mDictConfig._get_node\u001b[0;34m(self, key, validate_access, validate_key, throw_on_missing_value, throw_on_missing_key)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate_access:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    477\u001b[0m value: Optional[Node] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_content\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(key)\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/altegrad/venv_altegrad/lib/python3.10/site-packages/omegaconf/dictconfig.py:164\u001b[0m, in \u001b[0;36mDictConfig._validate_get\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not in struct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 164\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_and_raise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcause\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mConfigAttributeError\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/altegrad/venv_altegrad/lib/python3.10/site-packages/omegaconf/base.py:231\u001b[0m, in \u001b[0;36mNode._format_and_raise\u001b[0;34m(self, key, value, cause, msg, type_override)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_format_and_raise\u001b[39m(\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    225\u001b[0m     key: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m     type_override: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    230\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     \u001b[43mformat_and_raise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcause\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcause\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcause\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtype_override\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_override\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/altegrad/venv_altegrad/lib/python3.10/site-packages/omegaconf/_utils.py:899\u001b[0m, in \u001b[0;36mformat_and_raise\u001b[0;34m(node, key, value, msg, cause, type_override)\u001b[0m\n\u001b[1;32m    896\u001b[0m     ex\u001b[38;5;241m.\u001b[39mref_type \u001b[38;5;241m=\u001b[39m ref_type\n\u001b[1;32m    897\u001b[0m     ex\u001b[38;5;241m.\u001b[39mref_type_str \u001b[38;5;241m=\u001b[39m ref_type_str\n\u001b[0;32m--> 899\u001b[0m \u001b[43m_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/altegrad/venv_altegrad/lib/python3.10/site-packages/omegaconf/_utils.py:797\u001b[0m, in \u001b[0;36m_raise\u001b[0;34m(ex, cause)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    796\u001b[0m     ex\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 797\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex\u001b[38;5;241m.\u001b[39mwith_traceback(sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n",
      "\u001b[0;31mConfigAttributeError\u001b[0m: Key 'fixed_special_tokens' not in 'DataArgs'\n    full_key: data_args.fixed_special_tokens\n    reference_type=DataArgs\n    object_type=DataArgs"
     ]
    }
   ],
   "source": [
    "print(f\"{cfg.data_args.fixed_special_tokens=}\")\n",
    "print(f\"{cfg.use_sgd=}\")\n",
    "print(f\"{cfg.learning_rate=}\")\n",
    "print(f\"{cfg.weight_decay=}\")\n",
    "print(f\"{cfg.batch_size=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1000\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m i2 \u001b[38;5;241m=\u001b[39m i2[amax2 \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     61\u001b[0m amax2 \u001b[38;5;241m=\u001b[39m amax2[amax2 \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 62\u001b[0m score2_acc \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamax2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtot\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# first layer attn score probe conditioned on locations attended by second layer\u001b[39;00m\n\u001b[1;32m     65\u001b[0m score_cond_acc \u001b[38;5;241m=\u001b[39m (amax[i1, amax2] \u001b[38;5;241m==\u001b[39m amax2 \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "i = 0\n",
    "for i, (x, y, outs) in enumerate(iterate_batches(ds, batch_size=cfg.optim_args.batch_size, seed=cfg.seed)):\n",
    "    print(f\"Epoch {i}/{cfg.max_iters}\")\n",
    "    dt_data = time.time() - t\n",
    "    if cfg.max_iters is not None and i >= cfg.max_iters:\n",
    "        if cfg.save_dir is not None:\n",
    "            outfile.close()\n",
    "        break\n",
    "    \n",
    "    x = torch.from_numpy(x).to(device)\n",
    "    y = torch.from_numpy(y).to(device)\n",
    "    outs = torch.from_numpy(outs).to(device)\n",
    "\n",
    "    if i in freeze_until:  # unfreeze params\n",
    "        for name, p in model.named_parameters():\n",
    "            if name in freeze_until[i]:\n",
    "                p.requires_grad_(True)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(x)\n",
    "\n",
    "    if cfg.loss_head_only:\n",
    "        loss = F.cross_entropy(pred[outs >= 2], y[outs >= 2])\n",
    "    else:\n",
    "        loss = F.cross_entropy(pred.flatten(0, 1), y.flatten(0, 1))\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    dt = time.time() - t\n",
    "    t = time.time()\n",
    "\n",
    "    if i % cfg.eval_delta == 0:\n",
    "        if cfg.data_args.k > 0:\n",
    "            acc_tot = (pred.argmax(-1)[outs >= 1] == y[outs >= 1]).float().mean().item()\n",
    "            sl = 10\n",
    "            acc_start = (pred[:,:sl].argmax(-1)[outs[:,:sl] >= 1] == y[:,:sl][outs[:,:sl] >= 1]).float().mean().item()\n",
    "            el = 500\n",
    "            acc_end = (pred[:,-el:].argmax(-1)[outs[:,-el:] >= 2] == y[:,-el:][outs[:,-el:] >= 2]).float().mean().item()\n",
    "            loss_bigram = F.cross_entropy(pred[outs == 0,:], y[outs == 0]).item()\n",
    "            loss_head = F.cross_entropy(pred[outs >= 2,:], y[outs >= 2]).item()\n",
    "\n",
    "            # first layer attn scores probe\n",
    "            i1, i2 = torch.where(outs[:,:-1] >= 1)\n",
    "            i1_start, i2_start = torch.where(outs[:,:-1] == 1)\n",
    "            amax = attn_scores[:,0,:,:].argmax(-1)\n",
    "            score_acc = (amax[i1, i2 + 1] == i2).float().mean().item()\n",
    "            score_start_acc = (amax[i1_start, i2_start + 1] == i2_start).float().mean().item()\n",
    "\n",
    "            # second layer attn scores probe (check that attended token's prev token has correct condition)\n",
    "            i1, i2 = torch.where(outs >= 2)\n",
    "            amax2 = attn_scores2.squeeze(1)[i1,i2,:].argmax(-1)\n",
    "            score2_next_acc = (x[i1, amax2] == y[i1, i2]).float().mean().item()\n",
    "            pred_attended_acc = (x[i1, amax2] == pred[i1,i2].argmax(-1)).float().mean().item()\n",
    "\n",
    "            bad = (amax2 == 0).float().sum()\n",
    "            tot = amax2.shape[0]\n",
    "            i1 = i1[amax2 >= 1]\n",
    "            i2 = i2[amax2 >= 1]\n",
    "            amax2 = amax2[amax2 >= 1]\n",
    "            score2_acc = (x[i1, amax2 - 1] == x[i1, i2]).float().sum().item() / tot\n",
    "\n",
    "            # first layer attn score probe conditioned on locations attended by second layer\n",
    "            score_cond_acc = (amax[i1, amax2] == amax2 - 1).float().mean().item()\n",
    "\n",
    "            # second layer attn score probe conditioned on repeated tokens\n",
    "            i1, i2 = torch.where((outs >= 2) & (x == y))\n",
    "            amax1 = attn_scores.squeeze(1)[i1,i2,:].argmax(-1)\n",
    "            score1_repeat_val_acc = (x[i1, amax1] == y[i1, i2]).float().mean().item()\n",
    "            amax2 = attn_scores2.squeeze(1)[i1,i2,:].argmax(-1)\n",
    "            score2_repeat_val_acc = (x[i1, amax2] == y[i1, i2]).float().mean().item()\n",
    "            # score2_repeat_prev_acc = (amax2 == i2 - 1).float().mean().item()\n",
    "\n",
    "            if True:  # cfg.log_probes:\n",
    "                wo1_acc = test_wo1()\n",
    "                if cfg.model_args.final_ffn:\n",
    "                    ff1_loss = test_ff1()\n",
    "                else:\n",
    "                    ff1_loss = -1\n",
    "                wk0_acc = test_wk0()\n",
    "                wk0_64_acc = test_wk0(cutoff=64)\n",
    "                wk1_acc = test_wk1()\n",
    "\n",
    "            repeat_frac = (x[outs >= 1] == y[outs >= 1]).float().mean().item()\n",
    "\n",
    "            # OOD test (NOTE: do this after the probes sinces it messes hooks!)\n",
    "            with torch.no_grad():\n",
    "                pred_t = model(x_t)\n",
    "            acc_end_test = (pred_t[:,-el:].argmax(-1)[outs_t[:,-el:] >= 2] == y_t[:,-el:][outs_t[:,-el:] >= 2]).float().mean().item()\n",
    "\n",
    "            logging.info(\n",
    "                    f'''{i} ({dt_data:.2f}, {dt:.2f}, {t - t0:.2f}): loss: {loss.item():.4f} ({loss_bigram:.4f}, {loss_head:.4f}), \\\n",
    "acc: {acc_tot:.4f} ({acc_end:.4f} / {acc_end_test:.4f}) \\\n",
    "probes: {score_start_acc:.4f} / {score2_acc:.4f} / {score_cond_acc:.4f} / {pred_attended_acc:.4f} ({repeat_frac:.4f})'''\n",
    ")\n",
    "            if cfg.log_probes:\n",
    "                logging.info(f'memory probes wk0: {wk0_acc:.4f} ({wk0_64_acc:.4f}), wk1: {wk1_acc:.4f}, wo1: {wo1_acc:.4f}, ff1: {ff1_loss:.4f}')\n",
    "\n",
    "            curr_res = {'iter': i, 'loss': loss.item(), 'loss_bigram': loss_bigram, 'loss_head': loss_head,\n",
    "                        'acc_tot': acc_tot, 'acc_start': acc_start, 'acc_end': acc_end, 'acc_end_test': acc_end_test,\n",
    "                        'score_acc': score_acc, 'score_start_acc': score_start_acc, 'score2_acc': score2_acc,\n",
    "                        'score_cond_acc': score_cond_acc,\n",
    "                        'pred_attended_acc': pred_attended_acc, 'repeat_frac': repeat_frac,\n",
    "                        'wk0_acc': wk0_acc, 'wk0_64_acc': wk0_64_acc, 'wk1_acc': wk1_acc, 'wo1_acc': wo1_acc, 'ff1_loss': ff1_loss}\n",
    "\n",
    "            for name, p in model.named_parameters():\n",
    "                if p.requires_grad:\n",
    "                    curr_res['norm_' + name] = p.norm().item()\n",
    "                    curr_res['gradnorm_' + name] = p.grad.norm().item()\n",
    "\n",
    "            if cfg.log_norms:\n",
    "                param_norms = {\n",
    "                        'wk': [layer.attention.wk.weight.norm().item() for layer in model.layers],\n",
    "                        'wv': [layer.attention.wv.weight.norm().item() for layer in model.layers],\n",
    "                        'wo': [layer.attention.wo.weight.norm().item() for layer in model.layers],\n",
    "                        }\n",
    "                grad_norms = {\n",
    "                        'wk': [layer.attention.wk.weight.grad.norm().item() for layer in model.layers if layer.attention.wk.weight.requires_grad],\n",
    "                        'wv': [layer.attention.wv.weight.grad.norm().item() for layer in model.layers if layer.attention.wv.weight.requires_grad],\n",
    "                        'wo': [layer.attention.wo.weight.grad.norm().item() for layer in model.layers if layer.attention.wo.weight.requires_grad],\n",
    "                        }\n",
    "                logging.info(repr(param_norms))\n",
    "                logging.info(repr(grad_norms))\n",
    "            all_results.append(curr_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(all_results)\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.DataFrame.from_records(all_results)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"logs/2025_01_20_21_05_40_res.json\", \"r\") as f:\n",
    "    res = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_records(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter</th>\n",
       "      <th>loss</th>\n",
       "      <th>loss_bigram</th>\n",
       "      <th>loss_head</th>\n",
       "      <th>acc_tot</th>\n",
       "      <th>acc_start</th>\n",
       "      <th>acc_end</th>\n",
       "      <th>acc_end_test</th>\n",
       "      <th>score_acc</th>\n",
       "      <th>score_start_acc</th>\n",
       "      <th>...</th>\n",
       "      <th>wk0_64_acc</th>\n",
       "      <th>wk1_acc</th>\n",
       "      <th>wo1_acc</th>\n",
       "      <th>ff1_loss</th>\n",
       "      <th>norm_layers.0.attention.wk.weight</th>\n",
       "      <th>gradnorm_layers.0.attention.wk.weight</th>\n",
       "      <th>norm_layers.1.attention.wk.weight</th>\n",
       "      <th>gradnorm_layers.1.attention.wk.weight</th>\n",
       "      <th>norm_layers.1.attention.wo.weight</th>\n",
       "      <th>gradnorm_layers.1.attention.wo.weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.575071</td>\n",
       "      <td>4.450954</td>\n",
       "      <td>4.575071</td>\n",
       "      <td>0.011630</td>\n",
       "      <td>0.009340</td>\n",
       "      <td>0.011863</td>\n",
       "      <td>0.013984</td>\n",
       "      <td>0.021717</td>\n",
       "      <td>0.164777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.254825</td>\n",
       "      <td>0.072896</td>\n",
       "      <td>9.249850</td>\n",
       "      <td>0.104189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.540353</td>\n",
       "      <td>4.455684</td>\n",
       "      <td>4.540353</td>\n",
       "      <td>0.013311</td>\n",
       "      <td>0.007910</td>\n",
       "      <td>0.013244</td>\n",
       "      <td>0.014061</td>\n",
       "      <td>0.020190</td>\n",
       "      <td>0.164541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.254778</td>\n",
       "      <td>0.081149</td>\n",
       "      <td>9.249804</td>\n",
       "      <td>0.119260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.599963</td>\n",
       "      <td>4.452395</td>\n",
       "      <td>4.599963</td>\n",
       "      <td>0.012750</td>\n",
       "      <td>0.013734</td>\n",
       "      <td>0.012752</td>\n",
       "      <td>0.014164</td>\n",
       "      <td>0.020342</td>\n",
       "      <td>0.155236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.254715</td>\n",
       "      <td>0.088820</td>\n",
       "      <td>9.249736</td>\n",
       "      <td>0.141720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.557446</td>\n",
       "      <td>4.450966</td>\n",
       "      <td>4.557446</td>\n",
       "      <td>0.013546</td>\n",
       "      <td>0.013624</td>\n",
       "      <td>0.013306</td>\n",
       "      <td>0.014138</td>\n",
       "      <td>0.021539</td>\n",
       "      <td>0.160848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.254651</td>\n",
       "      <td>0.087281</td>\n",
       "      <td>9.249665</td>\n",
       "      <td>0.155967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.558529</td>\n",
       "      <td>4.447713</td>\n",
       "      <td>4.558529</td>\n",
       "      <td>0.012972</td>\n",
       "      <td>0.013486</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.014395</td>\n",
       "      <td>0.022542</td>\n",
       "      <td>0.161878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.254571</td>\n",
       "      <td>0.064013</td>\n",
       "      <td>9.249595</td>\n",
       "      <td>0.117203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   iter      loss  loss_bigram  loss_head   acc_tot  acc_start   acc_end  \\\n",
       "0     0  4.575071     4.450954   4.575071  0.011630   0.009340  0.011863   \n",
       "1     1  4.540353     4.455684   4.540353  0.013311   0.007910  0.013244   \n",
       "2     2  4.599963     4.452395   4.599963  0.012750   0.013734  0.012752   \n",
       "3     3  4.557446     4.450966   4.557446  0.013546   0.013624  0.013306   \n",
       "4     4  4.558529     4.447713   4.558529  0.012972   0.013486  0.013000   \n",
       "\n",
       "   acc_end_test  score_acc  score_start_acc  ...  wk0_64_acc  wk1_acc  \\\n",
       "0      0.013984   0.021717         0.164777  ...    0.031746      0.0   \n",
       "1      0.014061   0.020190         0.164541  ...    0.031746      0.0   \n",
       "2      0.014164   0.020342         0.155236  ...    0.031746      0.0   \n",
       "3      0.014138   0.021539         0.160848  ...    0.031746      0.0   \n",
       "4      0.014395   0.022542         0.161878  ...    0.031746      0.0   \n",
       "\n",
       "    wo1_acc  ff1_loss  norm_layers.0.attention.wk.weight  \\\n",
       "0  0.046154        -1                           9.254825   \n",
       "1  0.046154        -1                           9.254778   \n",
       "2  0.046154        -1                           9.254715   \n",
       "3  0.046154        -1                           9.254651   \n",
       "4  0.046154        -1                           9.254571   \n",
       "\n",
       "   gradnorm_layers.0.attention.wk.weight  norm_layers.1.attention.wk.weight  \\\n",
       "0                               0.072896                           9.249850   \n",
       "1                               0.081149                           9.249804   \n",
       "2                               0.088820                           9.249736   \n",
       "3                               0.087281                           9.249665   \n",
       "4                               0.064013                           9.249595   \n",
       "\n",
       "   gradnorm_layers.1.attention.wk.weight  norm_layers.1.attention.wo.weight  \\\n",
       "0                               0.104189                                NaN   \n",
       "1                               0.119260                                NaN   \n",
       "2                               0.141720                                NaN   \n",
       "3                               0.155967                                NaN   \n",
       "4                               0.117203                                NaN   \n",
       "\n",
       "   gradnorm_layers.1.attention.wo.weight  \n",
       "0                                    NaN  \n",
       "1                                    NaN  \n",
       "2                                    NaN  \n",
       "3                                    NaN  \n",
       "4                                    NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['iter', 'loss', 'loss_bigram', 'loss_head', 'acc_tot', 'acc_start',\n",
      "       'acc_end', 'acc_end_test', 'score_acc', 'score_start_acc', 'score2_acc',\n",
      "       'score_cond_acc', 'pred_attended_acc', 'repeat_frac', 'wk0_acc',\n",
      "       'wk0_64_acc', 'wk1_acc', 'wo1_acc', 'ff1_loss',\n",
      "       'norm_layers.0.attention.wk.weight',\n",
      "       'gradnorm_layers.0.attention.wk.weight',\n",
      "       'norm_layers.1.attention.wk.weight',\n",
      "       'gradnorm_layers.1.attention.wk.weight',\n",
      "       'norm_layers.1.attention.wo.weight',\n",
      "       'gradnorm_layers.1.attention.wo.weight'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.55.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.3.1 in /raid/home/detectionfeuxdeforet/caillaud_gab/altegrad/venv_altegrad/lib/python3.10/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: numpy>=1.23 in /raid/home/detectionfeuxdeforet/caillaud_gab/altegrad/venv_altegrad/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.0/325.0 kB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow>=8 in /raid/home/detectionfeuxdeforet/caillaud_gab/altegrad/venv_altegrad/lib/python3.10/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /raid/home/detectionfeuxdeforet/caillaud_gab/altegrad/venv_altegrad/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /raid/home/detectionfeuxdeforet/caillaud_gab/altegrad/venv_altegrad/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in /raid/home/detectionfeuxdeforet/caillaud_gab/altegrad/venv_altegrad/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Installing collected packages: kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.3 kiwisolver-1.4.8 matplotlib-3.10.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df[['wk0_acc','wk0_64_acc', 'wk1_acc', 'wo1_acc']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
